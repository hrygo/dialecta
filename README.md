<p align="center">
  <img src="https://img.shields.io/badge/Go-1.21+-00ADD8?style=flat&logo=go" alt="Go Version">
  <img src="https://img.shields.io/badge/License-MIT-green.svg" alt="License">
  <img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg" alt="PRs Welcome">
</p>

<h1 align="center">
  <br>
  ğŸ­ Dialecta
  <br>
</h1>

<h4 align="center">Multi-Persona AI Debate System â€” å¤šè§’è‰² AI è¾©è®ºç³»ç»Ÿ</h4>

<p align="center">
  é€šè¿‡<b>æ­£åæ–¹å¯¹æŠ—è¾©è®º</b> + <b>AI è£å†³</b>çš„å·¥ä½œæµï¼Œå…‹æœå•ä¸€ LLM çš„å¹»è§‰å’Œç›²ç›®é¡ºä»é—®é¢˜ã€‚
</p>

---

## âœ¨ Features

- ğŸ”„ **Multi-Persona Debate** â€” æ­£æ–¹æ”¯æŒã€åæ–¹åé©³ã€è£å†³æ–¹ç»¼åˆåˆ¤æ–­
- ğŸ”€ **Parallel Execution** â€” æ­£åæ–¹å¹¶è¡Œç”Ÿæˆï¼Œæå‡æ•ˆç‡
- ğŸŒŠ **Streaming Output** â€” å®æ—¶æµå¼è¾“å‡ºï¼Œæ‰€è§å³æ‰€å¾—
- ğŸ¨ **Modern CLI** â€” ç§‘æŠ€æ„Ÿ UIï¼Œä¸°å¯Œçš„é¢œè‰²å’Œè§†è§‰å…ƒç´ 
- ğŸ”Œ **Multi-Provider** â€” æ”¯æŒ DeepSeekã€Geminiã€DashScope (Qwen)
- âš™ï¸ **Flexible Config** â€” æ¯ä¸ªè§’è‰²å¯ç‹¬ç«‹é…ç½®ä¸åŒçš„ Provider å’Œ Model
- ğŸ¯ **8 Model Combinations** â€” äº¤äº’æ¨¡å¼æä¾› 8 ç§é¢„è®¾æ¨¡å‹ç»„åˆï¼Œå¿«é€Ÿé€‰æ‹©
- ğŸ“ **Structured Input** â€” äº¤äº’æ¨¡å¼æ”¯æŒé—®é¢˜+ä¸Šä¸‹æ–‡æ–‡ä»¶çš„ç»“æ„åŒ–è¾“å…¥

## ğŸ—ï¸ Architecture

![Dialecta Architecture](assets/architecture.png)

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/hrygo/dialecta.git
cd dialecta

# Build
make build

# Or install globally
make install
```

### Environment Setup

```bash
# Set API keys (configure based on your providers)
export DEEPSEEK_API_KEY="your-deepseek-api-key"
export GEMINI_API_KEY="your-gemini-api-key"        # or GOOGLE_API_KEY
export DASHSCOPE_API_KEY="your-dashscope-api-key"
```

### Usage

```bash
# Analyze a file
dialecta proposal.md

# Read from stdin
echo "æˆ‘ä»¬åº”è¯¥å¯åŠ¨ AI åˆ›ä¸šé¡¹ç›®" | dialecta -

# Interactive mode (with structured input support)
dialecta --interactive
dialecta -i             # Short form
# Features: Model selection + Question + Optional context file

# Quick access with Make commands
make ui                    # Interactive mode with 8 model combinations
make gemini                # All Gemini (Pro, Con, Judge)
make gemini-deepseek       # Gemini Judge, DeepSeek debate
make gemini-qwen           # Gemini Judge, Qwen debate  
make deepseek-qwen         # Gemini Judge, DeepSeek vs Qwen

# Custom providers
dialecta --pro-provider deepseek --con-provider dashscope --judge-provider gemini doc.md
```

## âš™ï¸ Configuration

### Supported Providers

| Provider  | Environment Variable                | Default Model           | Description       |
| --------- | ----------------------------------- | ----------------------- | ----------------- |
| DeepSeek  | `DEEPSEEK_API_KEY`                  | `deepseek-chat`         | DeepSeek Chat API |
| Gemini    | `GEMINI_API_KEY` / `GOOGLE_API_KEY` | `gemini-3-pro-preview`  | Google Gemini API |
| DashScope | `DASHSCOPE_API_KEY`                 | `qwen-plus`             | Alibaba Qwen API  |

### Default Role Configuration

| Role        | Provider  | Model                   | Temperature |
| ----------- | --------- | ----------------------- | ----------- |
| Affirmative | DeepSeek  | `deepseek-chat`         | 0.8         |
| Negative    | DashScope | `qwen-plus`             | 0.8         |
| Adjudicator | Gemini    | `gemini-3-pro-preview`  | 0.1         |

### Interactive Mode Combinations

When using `dialecta -i` or `make ui`, you can choose from 8 model combinations:

| ID | Combination | Judge | Pro | Con | Description |
|----|-------------|-------|-----|-----|-------------|
| 1 | All Gemini | Gemini | Gemini | Gemini | Highest quality analysis |
| 2 | Gemini Judge, DeepSeek Debate | Gemini | DeepSeek | DeepSeek | Gemini judgment + DeepSeek reasoning |
| 3 | Gemini Judge, DeepSeek vs Qwen | Gemini | DeepSeek | Qwen | Mixed debate perspectives |
| 4 | Gemini Judge, Qwen Debate | Gemini | Qwen | Qwen | Gemini judgment + Qwen debate |
| 5 | All DeepSeek | DeepSeek | DeepSeek | DeepSeek | Unified DeepSeek experience |
| 6 | DeepSeek Judge, DeepSeek vs Qwen | DeepSeek | DeepSeek | Qwen | DeepSeek judgment + mixed debate |
| 7 | DeepSeek Judge, Qwen Debate | DeepSeek | Qwen | Qwen | DeepSeek judgment + Qwen debate |
| 8 | All Qwen | Qwen | Qwen | Qwen | Unified Qwen experience |

### CLI Options

```
OPTIONS
  -pro-provider string    Provider for affirmative (default "deepseek")
  -pro-model string       Model for affirmative
  -con-provider string    Provider for negative (default "dashscope")
  -con-model string       Model for negative
  -judge-provider string  Provider for adjudicator (default "gemini")
  -judge-model string     Model for adjudicator
  -stream                 Enable streaming output (default true)
  -interactive            Interactive input mode
  -i                      Interactive input mode (shorthand)
```

## ğŸ“– Examples

### Basic Usage

```bash
# Analyze a business proposal
dialecta business-plan.md

# Quick test via stdin
echo "å…¬å¸åº”è¯¥å…¨é¢é‡‡ç”¨è¿œç¨‹åŠå…¬æ¨¡å¼" | dialecta -
```

### Interactive Mode

```bash
# Start interactive mode
dialecta -i

# Or use Make
make ui

# You'll see a menu to choose from 8 model combinations:
# ğŸŒŸ Gemini Judge:
#   [1] All Gemini
#   [2] Gemini Judge, DeepSeek Debate
#   [3] Gemini Judge, DeepSeek vs Qwen
#   [4] Gemini Judge, Qwen Debate
# âš¡ DeepSeek Judge:
#   [5] All DeepSeek
#   [6] DeepSeek Judge, DeepSeek vs Qwen
#   [7] DeepSeek Judge, Qwen Debate
# ğŸ”· Qwen Judge:
#   [8] All Qwen
```

**Structured Input with Context File**:

Interactive mode now supports two-step input for complex analysis:

```
# Step 1: Select model combination
â–¸ Enter your choice (1-8): 1

# Step 2: Enter your question
â‘  Enter your question or instruction:
   (Press ENTER twice to finish)
â–¸ è¯·åˆ†æè¿™ä»½ä»£ç çš„ä¼˜ç¼ºç‚¹
â–¸ é‡ç‚¹å…³æ³¨æ€§èƒ½å’Œå¯ç»´æŠ¤æ€§
â–¸ 

# Step 3: Optionally provide a context file
â‘¡ Enter context file path (optional, press ENTER to skip):
â–¸ ./internal/cli/input.go

âœ“ Question + Context file loaded
  â€¢ Question: 45 characters
  â€¢ Context file: ./internal/cli/input.go (5234 characters)
```

The program will automatically structure your input:

```
# ç”¨æˆ·é—®é¢˜

è¯·åˆ†æè¿™ä»½ä»£ç çš„ä¼˜ç¼ºç‚¹
é‡ç‚¹å…³æ³¨æ€§èƒ½å’Œå¯ç»´æŠ¤æ€§

---

# ä¸Šä¸‹æ–‡æ–‡ä»¶ï¼š./internal/cli/input.go

[File content...]
```

### Multi-Provider Setup

```bash
# Use DeepSeek for reasoning, Gemini for judgment
dialecta --judge-provider gemini --judge-model gemini-3-pro-preview proposal.md

# All Qwen models
dialecta --pro-provider dashscope --con-provider dashscope --judge-provider dashscope doc.md

# Mixed providers for diversity
dialecta --pro-provider deepseek --con-provider dashscope --judge-provider gemini idea.txt
```

### Production Workflow

```bash
# High-quality analysis with specific models
dialecta \
  --pro-provider deepseek --pro-model deepseek-chat \
  --con-provider dashscope --con-model qwen-max \
  --judge-provider gemini --judge-model gemini-3-pro-preview \
  important-decision.md
```

## ğŸ› ï¸ Development

### Prerequisites

- Go 1.21+
- Make

### Build & Test

```bash
# Format, lint, test, and build
make all

# Run tests
make test

# Run tests with coverage
make cover

# Build for current platform
make build

# Cross-platform build
make build-all

# Run linter
make lint

# Interactive mode with model selection
make ui

# Quick model combinations
make gemini               # All Gemini
make gemini-deepseek      # Gemini Judge + DeepSeek debate
make gemini-qwen          # Gemini Judge + Qwen debate
make deepseek-qwen        # Gemini Judge + DeepSeek vs Qwen

# Show all available commands
make help
```

### Project Structure

```
dialecta/
â”œâ”€â”€ cmd/dialecta/        # CLI entry point
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ cli/             # CLI components (UI, input, flags)
â”‚   â”œâ”€â”€ config/          # Configuration management
â”‚   â”œâ”€â”€ debate/          # Debate orchestration
â”‚   â”œâ”€â”€ llm/             # LLM client implementations
â”‚   â””â”€â”€ prompt/          # Prompt templates
â”œâ”€â”€ Makefile
â”œâ”€â”€ go.mod
â””â”€â”€ README.md
```

## ğŸ“Š Test Coverage

| Package           | Coverage |
| ----------------- | -------- |
| `internal/config` | 100%     |
| `internal/prompt` | 100%     |
| `internal/debate` | 70.8%    |
| `internal/cli`    | 60.9%    |
| `internal/llm`    | 40%*     |

\* LLM package requires integration tests with real API calls

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'feat: add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [DeepSeek](https://deepseek.com/) for their powerful AI models
- [Google Gemini](https://ai.google.dev/) for their multimodal capabilities
- [Alibaba DashScope](https://dashscope.aliyun.com/) for Qwen models

---

<p align="center">
  Made with â¤ï¸ by <a href="https://github.com/hrygo">hrygo</a>
</p>
